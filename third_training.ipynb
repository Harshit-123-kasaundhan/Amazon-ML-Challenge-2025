{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a784da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Image embeddings: (42800, 768)\n",
      "✓ Text embeddings: (42800, 384)\n",
      "✓ Loaded CSV: 57200 rows\n",
      "Feature matrix: (42800, 1188)\n",
      "\n",
      "✓ Predictions saved to 'resnet_predictions.csv'\n",
      "\n",
      "Sample predictions:\n",
      " sample_id     price\n",
      "    100179 18.377113\n",
      "    245611 17.560154\n",
      "    146263 23.193251\n",
      "     95658  6.979241\n",
      "     36806 21.656097\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pickle\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define the ResidualBlock class (same as in training)\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim, dim),\n",
    "            torch.nn.BatchNorm1d(dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(dim, dim),\n",
    "            torch.nn.BatchNorm1d(dim)\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.block(x) + x)\n",
    "\n",
    "# Define the ResNetRegressor class (same as in training)\n",
    "class ResNetRegressor(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ResNetRegressor, self).__init__()\n",
    "        self.input_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.res_blocks = torch.nn.Sequential(\n",
    "            ResidualBlock(512),\n",
    "            ResidualBlock(512),\n",
    "            ResidualBlock(512)\n",
    "        )\n",
    "        self.output_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.res_blocks(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Paths\n",
    "EMBEDDINGS_DIR = r'D:\\amazon ml\\test_embeddings'\n",
    "CSV_PATH = 'test/merged_test_with_image.csv'  # Replace with your test CSV path if different\n",
    "OUTPUT_DIR = 'fast_ensemble_models'\n",
    "OUTPUT_CSV = 'resnet_predictions.csv'\n",
    "\n",
    "# Load preprocessing objects\n",
    "with open(os.path.join(OUTPUT_DIR, 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "with open(os.path.join(OUTPUT_DIR, 'unit_encoder.pkl'), 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# Load and process embeddings\n",
    "image_pooled_list = []\n",
    "text_pooled_list = []\n",
    "for batch_idx in range(428):\n",
    "    batch_dir = os.path.join(EMBEDDINGS_DIR, f'batch_{batch_idx}')\n",
    "    image_emb_path = os.path.join(batch_dir, 'image_embeddings.pt')\n",
    "    text_emb_path = os.path.join(batch_dir, 'text_embeddings.pt')\n",
    "    \n",
    "    if os.path.exists(image_emb_path) and os.path.exists(text_emb_path):\n",
    "        try:\n",
    "            image_emb = torch.load(image_emb_path)\n",
    "            text_emb = torch.load(text_emb_path)\n",
    "            image_pooled = image_emb.mean(dim=1).numpy()\n",
    "            text_pooled = text_emb.mean(dim=1).numpy()\n",
    "            image_pooled_list.append(image_pooled)\n",
    "            text_pooled_list.append(text_pooled)\n",
    "            del image_emb, text_emb\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "if not image_pooled_list or not text_pooled_list:\n",
    "    raise ValueError(\"No valid embeddings loaded.\")\n",
    "\n",
    "image_pooled = np.concatenate(image_pooled_list, axis=0)\n",
    "text_pooled = np.concatenate(text_pooled_list, axis=0)\n",
    "print(f\"✓ Image embeddings: {image_pooled.shape}\")\n",
    "print(f\"✓ Text embeddings: {text_pooled.shape}\")\n",
    "del image_pooled_list, text_pooled_list\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"✓ Loaded CSV: {len(df)} rows\")\n",
    "\n",
    "# Align data\n",
    "num_samples = min(len(df), image_pooled.shape[0], text_pooled.shape[0])\n",
    "df = df.iloc[:num_samples].reset_index(drop=True)\n",
    "image_pooled = image_pooled[:num_samples]\n",
    "text_pooled = text_pooled[:num_samples]\n",
    "\n",
    "# Create features\n",
    "embeddings_concat = np.concatenate([image_pooled, text_pooled], axis=1)\n",
    "unit_encoded = encoder.transform(df[['unit']])\n",
    "features = np.concatenate([embeddings_concat, df[['value']].to_numpy(), unit_encoded], axis=1)\n",
    "print(f\"Feature matrix: {features.shape}\")\n",
    "\n",
    "# Scale features\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "# Convert to tensor\n",
    "features_tensor = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "\n",
    "# Load the ResNet model\n",
    "input_dim = features.shape[1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetRegressor(input_dim).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'resnet_model.pth')))\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    features_tensor = features_tensor.to(device)\n",
    "    predictions = model(features_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Create output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'sample_id': df['sample_id'],\n",
    "    'price': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\n✓ Predictions saved to '{OUTPUT_CSV}'\")\n",
    "\n",
    "# Print sample output\n",
    "print(\"\\nSample predictions:\")\n",
    "print(output_df.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc298bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "battery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
