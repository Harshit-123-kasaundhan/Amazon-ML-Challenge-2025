{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a675ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning catalog content...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75000/75000 [00:05<00:00, 14912.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved cleaned file as: test/train_clean.csv\n",
      "   sample_id                              catalog_content_clean\n",
      "0     100179  Item Name is Rani 14, Spice Eshamaya's Mango C...\n",
      "1     245611  Item Name is Natural MILK TEA Flavoring extrac...\n",
      "2     146263  Item Name is Honey Filled Hard Candy, Bulk Pac...\n",
      "3      95658  Item Name is Vlasic Snack'mm's Kosher Dill 16 ...\n",
      "4      36806  Item Name is McCormick Culinary Vanilla Extrac...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_catalog(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Normalize line breaks and spaces\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "    \n",
    "    # Split by common bullet or delimiter patterns\n",
    "    parts = re.split(r'[‚Ä¢;|,‚Ä¢\\-‚Äì‚óè‚óÜ‚ñ∂‚Üí\\t]+', text)\n",
    "    parts = [p.strip() for p in parts if len(p.strip()) > 1]\n",
    "\n",
    "    # Try to make each specification human-readable\n",
    "    clean_parts = []\n",
    "    for p in parts:\n",
    "        # If looks like key:value ‚Üí reformat it\n",
    "        if \":\" in p:\n",
    "            key, val = p.split(\":\", 1)\n",
    "            clean_parts.append(f\"{key.strip()} is {val.strip()}\")\n",
    "        elif \"=\" in p:\n",
    "            key, val = p.split(\"=\", 1)\n",
    "            clean_parts.append(f\"{key.strip()} is {val.strip()}\")\n",
    "        else:\n",
    "            clean_parts.append(p)\n",
    "\n",
    "    # Join into one line, separated by commas\n",
    "    clean_text = \", \".join(clean_parts)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# === MAIN ===\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "print(\"Cleaning catalog content...\")\n",
    "tqdm.pandas()\n",
    "df[\"catalog_content_clean\"] = df[\"catalog_content\"].progress_apply(clean_catalog)\n",
    "\n",
    "# Keep only required columns\n",
    "clean_df = df[[\"sample_id\", \"catalog_content_clean\"]]\n",
    "\n",
    "# Save cleaned CSV\n",
    "output_path = \"test/train_clean.csv\"\n",
    "clean_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved cleaned file as: {output_path}\")\n",
    "print(clean_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d93bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning catalog_content column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75000/75000 [00:14<00:00, 5170.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved at: test/test_clean.csv\n",
      "   sample_id                              catalog_content_clean\n",
      "0     100179  Rani 14, Spice Eshamaya's Mango Chutney (India...\n",
      "1     245611  Natural MILK TEA Flavoring extract by HALO PAN...\n",
      "2     146263  Honey Filled Hard Candy, Bulk Pack 2 Pounds, I...\n",
      "3      95658  Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2...\n",
      "4      36806  McCormick Culinary Vanilla Extract, 32 fl oz, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_catalog(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Replace newlines and normalize spaces\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip()\n",
    "\n",
    "    # Remove field names like \"Bullet Point 1:\", \"Bullet Point 2:\", \"Item Name:\", \"Value:\", \"Unit:\" etc.\n",
    "    text = re.sub(r'\\b[Bb]ullet\\s*[Pp]oint\\s*\\d*\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Ii]tem\\s*[Nn]ame\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Vv]alue\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Uu]nit\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Bb]rand\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Dd]escription\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Ss]pecifications\\s*:', '', text)\n",
    "\n",
    "    # Split text on punctuation or bullet-like delimiters\n",
    "    parts = re.split(r'[‚Ä¢;|,‚Ä¢\\-‚Äì‚óè‚óÜ‚ñ∂‚Üí\\t]+', text)\n",
    "    parts = [p.strip() for p in parts if len(p.strip()) > 1]\n",
    "\n",
    "    # Join into a single readable line\n",
    "    clean_text = \", \".join(parts)\n",
    "\n",
    "    # Remove redundant spaces and punctuation\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    clean_text = re.sub(r'\\s+,', ',', clean_text)\n",
    "    clean_text = clean_text.strip(' ,')\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "print(\"Cleaning catalog_content column...\")\n",
    "tqdm.pandas()\n",
    "df[\"catalog_content_clean\"] = df[\"catalog_content\"].progress_apply(clean_catalog)\n",
    "\n",
    "# Keep only the desired columns\n",
    "clean_df = df[[\"sample_id\", \"catalog_content_clean\"]]\n",
    "\n",
    "# Save the cleaned version\n",
    "output_path = \"test/test_clean.csv\"\n",
    "clean_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned dataset saved at: {output_path}\")\n",
    "print(clean_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e0f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Cleaning catalog_content column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75000/75000 [00:20<00:00, 3688.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved as: test/test_clean2.csv\n",
      "   sample_id                              catalog_content_clean\n",
      "0     100179  Rani 14, Spice Eshamaya's Mango Chutney (India...\n",
      "1     245611  Natural MILK TEA Flavoring extract by HALO PAN...\n",
      "2     146263  Honey Filled Hard Candy, Bulk Pack 2 Pounds, I...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_catalog(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Replace newlines and normalize spaces\n",
    "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Remove field names and common prefixes\n",
    "    text = re.sub(r'\\b[Bb]ullet\\s*[Pp]oint\\s*\\d*\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Ii]tem\\s*[Nn]ame\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Vv]alue\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Uu]nit\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Bb]rand\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Dd]escription\\s*:', '', text)\n",
    "    text = re.sub(r'\\b[Ss]pecifications\\s*:', '', text)\n",
    "\n",
    "    # Split on patterns that indicate new items or bullet content\n",
    "    parts = re.split(r'(?:[.?!]\\s+|\\s{2,}|,?\\s*[‚Ä¢\\-‚Äì‚óè‚óÜ‚ñ∂‚Üí]\\s*|,?\\s*Bullet\\s*Point\\s*\\d*\\s*)', text)\n",
    "    parts = [p.strip() for p in parts if len(p.strip()) > 1]\n",
    "\n",
    "    # Add comma after every bullet/segment\n",
    "    clean_parts = []\n",
    "    for p in parts:\n",
    "        if not p.endswith(\",\"):\n",
    "            p = p + \",\"\n",
    "        clean_parts.append(p)\n",
    "\n",
    "    # Join them together\n",
    "    clean_text = \" \".join(clean_parts)\n",
    "\n",
    "    # Clean redundant commas and spaces\n",
    "    clean_text = re.sub(r'\\s+,', ',', clean_text)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    clean_text = clean_text.strip(' ,')\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "print(\"Loading training data...\")\n",
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "print(\"Cleaning catalog_content column...\")\n",
    "tqdm.pandas()\n",
    "df[\"catalog_content_clean\"] = df[\"catalog_content\"].progress_apply(clean_catalog)\n",
    "\n",
    "# Keep only desired columns\n",
    "clean_df = df[[\"sample_id\", \"catalog_content_clean\"]]\n",
    "\n",
    "# Save to file\n",
    "output_path = \"test/test_clean2.csv\"\n",
    "clean_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned dataset saved as: {output_path}\")\n",
    "print(clean_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f202dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New dataset saved at: test/test_with_product_name.csv\n",
      "   sample_id                                       product_name  \\\n",
      "0     100179                                            Rani 14   \n",
      "1     245611  Natural MILK TEA Flavoring extract by HALO PAN...   \n",
      "2     146263                            Honey Filled Hard Candy   \n",
      "3      95658    Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)   \n",
      "4      36806                 McCormick Culinary Vanilla Extract   \n",
      "\n",
      "                               catalog_content_clean  \n",
      "0  Rani 14, Spice Eshamaya's Mango Chutney (India...  \n",
      "1  Natural MILK TEA Flavoring extract by HALO PAN...  \n",
      "2  Honey Filled Hard Candy, Bulk Pack 2 Pounds, I...  \n",
      "3  Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2...  \n",
      "4  McCormick Culinary Vanilla Extract, 32 fl oz, ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned dataset\n",
    "df = pd.read_csv(\"test/test_clean2.csv\")\n",
    "\n",
    "def extract_product_name(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Split by comma and take the first segment\n",
    "    first_part = text.split(\",\")[0].strip()\n",
    "\n",
    "    # Remove extra spaces or stray punctuation\n",
    "    first_part = first_part.strip(' .,:;')\n",
    "    return first_part\n",
    "\n",
    "# Apply the extraction\n",
    "df[\"product_name\"] = df[\"catalog_content_clean\"].apply(extract_product_name)\n",
    "\n",
    "# Reorder columns (optional)\n",
    "df = df[[\"sample_id\", \"product_name\", \"catalog_content_clean\"]]\n",
    "\n",
    "# Save to a new CSV\n",
    "output_path = \"test/test_with_product_name.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ New dataset saved at: {output_path}\")\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c406eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New file saved at: test/value_unit.csv\n",
      "   value   unit\n",
      "0   10.5  Ounce\n",
      "1    2.0  Fl Oz\n",
      "2   32.0  Ounce\n",
      "3    2.0  Count\n",
      "4   32.0  Fl Oz\n",
      "5   16.0  Ounce\n",
      "6   45.0  Ounce\n",
      "7    1.0  Count\n",
      "8  180.0     oz\n",
      "9   18.0  Ounce\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the original train.csv\n",
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Functions to extract \"Value\" and \"Unit\" fields\n",
    "def extract_value(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(r'Value\\s*:\\s*([0-9]*\\.?[0-9]+)', text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def extract_unit(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(r'Unit\\s*:\\s*([A-Za-z ]+)', text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# Apply the extraction\n",
    "df[\"value\"] = df[\"catalog_content\"].apply(extract_value)\n",
    "df[\"unit\"] = df[\"catalog_content\"].apply(extract_unit)\n",
    "\n",
    "# Keep only required columns\n",
    "value_unit_df = df[[\"value\", \"unit\"]]\n",
    "\n",
    "# Save to new CSV\n",
    "output_path = \"test/value_unit.csv\"\n",
    "value_unit_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ New file saved at: {output_path}\")\n",
    "print(value_unit_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23898640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ New file saved at: test/value_unit_with_id.csv\n",
      "   sample_id  value   unit\n",
      "0     100179   10.5  Ounce\n",
      "1     245611    2.0  Fl Oz\n",
      "2     146263   32.0  Ounce\n",
      "3      95658    2.0  Count\n",
      "4      36806   32.0  Fl Oz\n",
      "5     148239   16.0  Ounce\n",
      "6      92659   45.0  Ounce\n",
      "7       3780    1.0  Count\n",
      "8     196940  180.0     oz\n",
      "9      20472   18.0  Ounce\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load original train.csv\n",
    "df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# Functions to extract Value and Unit\n",
    "def extract_value(text):\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    match = re.search(r'Value\\s*:\\s*([0-9]*\\.?[0-9]+)', text)\n",
    "    if match:\n",
    "        return float(match.group(1).strip())\n",
    "    return 0  # default if not found\n",
    "\n",
    "def extract_unit(text):\n",
    "    if pd.isna(text):\n",
    "        return \"None\"\n",
    "    match = re.search(r'Unit\\s*:\\s*([A-Za-z ]+)', text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return \"None\"  # default if not found\n",
    "\n",
    "# Apply extraction\n",
    "df[\"value\"] = df[\"catalog_content\"].apply(extract_value)\n",
    "df[\"unit\"] = df[\"catalog_content\"].apply(extract_unit)\n",
    "\n",
    "# Keep sample_id + value + unit\n",
    "value_unit_df = df[[\"sample_id\", \"value\", \"unit\"]]\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"test/value_unit_with_id.csv\"\n",
    "value_unit_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ New file saved at: {output_path}\")\n",
    "print(value_unit_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad00eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Units converted to lowercase and saved at: test/value_unit_with_id_lower.csv\n",
      "   sample_id  value   unit\n",
      "0     100179   10.5  ounce\n",
      "1     245611    2.0  fl oz\n",
      "2     146263   32.0  ounce\n",
      "3      95658    2.0  count\n",
      "4      36806   32.0  fl oz\n",
      "5     148239   16.0  ounce\n",
      "6      92659   45.0  ounce\n",
      "7       3780    1.0  count\n",
      "8     196940  180.0     oz\n",
      "9      20472   18.0  ounce\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"test/value_unit_with_id.csv\")\n",
    "\n",
    "# Convert all units to lowercase\n",
    "df['unit'] = df['unit'].str.lower()\n",
    "\n",
    "# Save back to CSV (overwrite or new file)\n",
    "output_path = \"test/value_unit_with_id_lower.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Units converted to lowercase and saved at: {output_path}\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3a2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total products: 75000\n",
      "Products with missing unit (None): 0\n",
      "Percentage missing unit: 0.00%\n",
      "\n",
      "Count of products per unit type:\n",
      "unit\n",
      "ounce                   44022\n",
      "count                   18207\n",
      "fl oz                   11332\n",
      "none                      958\n",
      "pound                     202\n",
      "gm                         49\n",
      "ct                         49\n",
      "lb                         34\n",
      "each                       26\n",
      "pack                       21\n",
      "ml                         15\n",
      "bottle                      9\n",
      "liters                      7\n",
      "can                         6\n",
      "kg                          6\n",
      "bag                         6\n",
      "jar                         4\n",
      "pounds                      4\n",
      "per carton                  3\n",
      "box                         3\n",
      "k                           3\n",
      "case                        3\n",
      "piece                       3\n",
      "product                     2\n",
      "sq ft                       2\n",
      "pouch                       2\n",
      "per box                     2\n",
      "gr                          2\n",
      "tea bags                    2\n",
      "foot                        2\n",
      "paper cupcake liners        2\n",
      "unit                        1\n",
      "ltr                         1\n",
      "ziplock bags                1\n",
      "bottles                     1\n",
      "capsule                     1\n",
      "in                          1\n",
      "cm                          1\n",
      "units                       1\n",
      "comes as a single           1\n",
      "per package                 1\n",
      "bucket                      1\n",
      "carton                      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of products per unit type:\n",
      "unit\n",
      "ounce                   58.696000\n",
      "count                   24.276000\n",
      "fl oz                   15.109333\n",
      "none                     1.277333\n",
      "pound                    0.269333\n",
      "gm                       0.065333\n",
      "ct                       0.065333\n",
      "lb                       0.045333\n",
      "each                     0.034667\n",
      "pack                     0.028000\n",
      "ml                       0.020000\n",
      "bottle                   0.012000\n",
      "liters                   0.009333\n",
      "can                      0.008000\n",
      "kg                       0.008000\n",
      "bag                      0.008000\n",
      "jar                      0.005333\n",
      "pounds                   0.005333\n",
      "per carton               0.004000\n",
      "box                      0.004000\n",
      "k                        0.004000\n",
      "case                     0.004000\n",
      "piece                    0.004000\n",
      "product                  0.002667\n",
      "sq ft                    0.002667\n",
      "pouch                    0.002667\n",
      "per box                  0.002667\n",
      "gr                       0.002667\n",
      "tea bags                 0.002667\n",
      "foot                     0.002667\n",
      "paper cupcake liners     0.002667\n",
      "unit                     0.001333\n",
      "ltr                      0.001333\n",
      "ziplock bags             0.001333\n",
      "bottles                  0.001333\n",
      "capsule                  0.001333\n",
      "in                       0.001333\n",
      "cm                       0.001333\n",
      "units                    0.001333\n",
      "comes as a single        0.001333\n",
      "per package              0.001333\n",
      "bucket                   0.001333\n",
      "carton                   0.001333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"dataset/value_unit_standardized.csv\")\n",
    "\n",
    "# Total number of products\n",
    "total_products = len(df)\n",
    "\n",
    "# Count how many have 'None' as unit\n",
    "none_count = (df['unit'] == \"None\").sum()\n",
    "print(f\"Total products: {total_products}\")\n",
    "print(f\"Products with missing unit (None): {none_count}\")\n",
    "print(f\"Percentage missing unit: {none_count / total_products * 100:.2f}%\\n\")\n",
    "\n",
    "# Count of products per unit type\n",
    "unit_counts = df['unit'].value_counts()\n",
    "print(\"Count of products per unit type:\")\n",
    "print(unit_counts)\n",
    "\n",
    "# Optional: percentage per unit\n",
    "unit_percent = df['unit'].value_counts(normalize=True) * 100\n",
    "print(\"\\nPercentage of products per unit type:\")\n",
    "print(unit_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c2cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Standardized units saved at: test/value_unit_standardized.csv\n",
      "unit\n",
      "ounce                                    43914\n",
      "count                                    18187\n",
      "fl oz                                    11406\n",
      "none                                      1031\n",
      "pound                                      200\n",
      "ct                                          39\n",
      "pack                                        36\n",
      "gm                                          35\n",
      "each                                        23\n",
      "lb                                          18\n",
      "ml                                          17\n",
      "bottle                                       9\n",
      "liters                                       7\n",
      "bag                                          7\n",
      "product                                      5\n",
      "box                                          5\n",
      "tea bags                                     4\n",
      "foot                                         4\n",
      "jar                                          4\n",
      "ea                                           3\n",
      "paper cupcake liners                         3\n",
      "k                                            3\n",
      "packet                                       3\n",
      "pac                                          2\n",
      "sq ft                                        2\n",
      "piece                                        2\n",
      "per package                                  2\n",
      "gallon                                       2\n",
      "lbs                                          2\n",
      "kg                                           2\n",
      "sugar substitute                             1\n",
      "cou                                          1\n",
      "pieces                                       1\n",
      "gallons                                      1\n",
      "jars                                         1\n",
      "pouch                                        1\n",
      "capsules                                     1\n",
      "case                                         1\n",
      "st                                           1\n",
      "pounds                                       1\n",
      "tin                                          1\n",
      "liter                                        1\n",
      "milliliters                                  1\n",
      "sachet                                       1\n",
      "unit                                         1\n",
      "kit                                          1\n",
      "ltr                                          1\n",
      "g                                            1\n",
      "fluid                                        1\n",
      "m                                            1\n",
      "millilitro                                   1\n",
      "container                                    1\n",
      "comes as a single dispenser unit with        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"test/value_unit_with_id_lower.csv\")  # Already lowercase\n",
    "\n",
    "# Mapping of variations ‚Üí standardized units\n",
    "unit_mapping = {\n",
    "    \"oz\": \"ounce\",\n",
    "    \"ounces\": \"ounce\",\n",
    "    \"fluid ounce\": \"fl oz\",\n",
    "    \"fl\": \"fl oz\",\n",
    "    \"fl oz\": \"fl oz\",\n",
    "    \"fl ounce\": \"fl oz\",\n",
    "    \"fluid ounces\": \"fl oz\",\n",
    "    \"packs\": \"pack\",\n",
    "    \"pack\": \"pack\",\n",
    "    \"mililitro\": \"ml\",\n",
    "    \"milliliter\": \"ml\",\n",
    "    \"millilitre\": \"ml\",\n",
    "    \"ml\": \"ml\",\n",
    "    \"gram\": \"gm\",\n",
    "    \"gramm\": \"gm\",\n",
    "    \"grams\": \"gm\",\n",
    "    \"gm\": \"gm\",\n",
    "    \"none\": \"none\"   # Keep 'none' as is\n",
    "}\n",
    "\n",
    "# Function to standardize units\n",
    "def standardize_unit(unit):\n",
    "    if pd.isna(unit):\n",
    "        return \"none\"\n",
    "    unit = unit.strip().lower()\n",
    "    return unit_mapping.get(unit, unit)  # default to original if not in mapping\n",
    "\n",
    "# Apply mapping\n",
    "df['unit'] = df['unit'].apply(standardize_unit)\n",
    "\n",
    "# Save cleaned CSV\n",
    "output_path = \"test/value_unit_standardized.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Standardized units saved at: {output_path}\")\n",
    "print(df['unit'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f3bcba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merged dataset saved at: test/merged_train.csv\n",
      "   sample_id                                       product_name  \\\n",
      "0     100179                                            Rani 14   \n",
      "1     245611  Natural MILK TEA Flavoring extract by HALO PAN...   \n",
      "2     146263                            Honey Filled Hard Candy   \n",
      "3      95658    Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)   \n",
      "4      36806                 McCormick Culinary Vanilla Extract   \n",
      "\n",
      "                               catalog_content_clean  value   unit  \n",
      "0  Rani 14, Spice Eshamaya's Mango Chutney (India...   10.5  ounce  \n",
      "1  Natural MILK TEA Flavoring extract by HALO PAN...    2.0  fl oz  \n",
      "2  Honey Filled Hard Candy, Bulk Pack 2 Pounds, I...   32.0  ounce  \n",
      "3  Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2...    2.0  count  \n",
      "4  McCormick Culinary Vanilla Extract, 32 fl oz, ...   32.0  fl oz  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSVs\n",
    "df_main = pd.read_csv(\"test/test_with_product_name.csv\")  # sample_id, product_name, catalog_content_clean, price\n",
    "df_value_unit = pd.read_csv(\"test/value_unit_standardized.csv\")  # sample_id, value, unit\n",
    "\n",
    "# Merge on sample_id (inner join keeps only matching rows)\n",
    "merged_df = pd.merge(df_main, df_value_unit, on=\"sample_id\", how=\"left\")  # left join keeps all main rows\n",
    "\n",
    "# Optional: reorder columns\n",
    "merged_df = merged_df[[\"sample_id\", \"product_name\", \"catalog_content_clean\", \"value\", \"unit\"]]\n",
    "\n",
    "# Save merged CSV\n",
    "output_path = \"test/merged_train.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Merged dataset saved at: {output_path}\")\n",
    "print(merged_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c38c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved to: test/merged_test_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load your merged CSV\n",
    "df = pd.read_csv(\"test/merged_test.csv\")\n",
    "\n",
    "# Function to remove emojis and special symbols\n",
    "def remove_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # Remove all characters that are NOT basic printable ASCII\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "# Apply to catalog_content_clean and product_name\n",
    "df['catalog_content_clean'] = df['catalog_content_clean'].apply(remove_emojis)\n",
    "df['product_name'] = df['product_name'].apply(remove_emojis)\n",
    "\n",
    "# Save cleaned version\n",
    "output_path = \"test/merged_test_cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned dataset saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a886bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added image column using sample_id. Saved to: test/merged_test_with_image.csv\n",
      "   sample_id                                       product_name  \\\n",
      "0     100179                                            Rani 14   \n",
      "1     245611  Natural MILK TEA Flavoring extract by HALO PAN...   \n",
      "2     146263                            Honey Filled Hard Candy   \n",
      "3      95658    Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2)   \n",
      "4      36806                 McCormick Culinary Vanilla Extract   \n",
      "\n",
      "                               catalog_content_clean  value   unit       image  \n",
      "0  Rani 14, Spice Eshamaya's Mango Chutney (India...   10.5  ounce  100179.jpg  \n",
      "1  Natural MILK TEA Flavoring extract by HALO PAN...    2.0  fl oz  245611.jpg  \n",
      "2  Honey Filled Hard Candy, Bulk Pack 2 Pounds, I...   32.0  ounce  146263.jpg  \n",
      "3  Vlasic Snack'mm's Kosher Dill 16 Oz (Pack of 2...    2.0  count   95658.jpg  \n",
      "4  McCormick Culinary Vanilla Extract, 32 fl oz, ...   32.0  fl oz   36806.jpg  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your merged CSV\n",
    "df = pd.read_csv(\"test/merged_test_cleaned.csv\")\n",
    "\n",
    "# Add new column 'image' using sample_id\n",
    "df['image'] = df['sample_id'].astype(str) + '.jpg'\n",
    "\n",
    "# Save updated CSV\n",
    "output_path = \"test/merged_test_with_image.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Added image column using sample_id. Saved to: {output_path}\")\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d845c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 74999 image names to present_images.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your image folder\n",
    "IMAGE_FOLDER = \"test_images/test_images\"\n",
    "\n",
    "# List all files in the folder\n",
    "image_files = [f for f in os.listdir(IMAGE_FOLDER) if os.path.isfile(os.path.join(IMAGE_FOLDER, f))]\n",
    "\n",
    "# Create a DataFrame\n",
    "df_images = pd.DataFrame(image_files, columns=[\"image\"])\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"present_images.csv\"\n",
    "df_images.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(df_images)} image names to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effc4859",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m second_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(second_csv_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extract image names\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m first_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mfirst_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))  \u001b[38;5;66;03m# Convert to set for efficient comparison\u001b[39;00m\n\u001b[0;32m     13\u001b[0m second_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(second_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Find images in second CSV but not in first\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files (adjust paths as needed)\n",
    "first_csv_path = 'resnet_predictions.csv'  # Replace with your first CSV path\n",
    "second_csv_path = 'p1.csv'  # Replace with your second CSV path (e.g., train.csv)\n",
    "\n",
    "# Read CSVs\n",
    "first_df = pd.read_csv(first_csv_path)\n",
    "second_df = pd.read_csv(second_csv_path)\n",
    "\n",
    "# Extract image names\n",
    "first_images = set(first_df['image'].astype(str))  # Convert to set for efficient comparison\n",
    "second_images = set(second_df['image'].astype(str))\n",
    "\n",
    "# Find images in second CSV but not in first\n",
    "missing_images = second_images - first_images\n",
    "\n",
    "# Convert to list for output\n",
    "missing_images_list = sorted(list(missing_images))\n",
    "\n",
    "# Print results\n",
    "print(f\"Images in second CSV but not in first CSV ({len(missing_images_list)}):\")\n",
    "for img in missing_images_list:\n",
    "    print(img)\n",
    "\n",
    "# Optionally, save to a new CSV\n",
    "output_df = pd.DataFrame({'image': missing_images_list})\n",
    "output_df.to_csv('missing_images.csv', index=False)\n",
    "print(\"Results saved to 'missing_images.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02171821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Data Types:\n",
      " sample_id      int64\n",
      "price        float64\n",
      "dtype: object\n",
      "\n",
      "üßÆ Integer Columns: ['sample_id']\n",
      "\n",
      "üî§ String Columns: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"predictions/sample_test_out.csv\")\n",
    "\n",
    "# Get data types of each column\n",
    "print(\"Column Data Types:\\n\", df.dtypes)\n",
    "\n",
    "# Separate integer and string columns\n",
    "int_columns = df.select_dtypes(include=['int64', 'int32']).columns.tolist()\n",
    "str_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"\\nüßÆ Integer Columns:\", int_columns)\n",
    "print(\"\\nüî§ String Columns:\", str_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da3df37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/dinov2-base/resolve/main/preprocessor_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FBD0F7E3E0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 5f693e30-5ff4-4e62-9054-2ace0f1ab1df)')' thrown while requesting HEAD https://huggingface.co/facebook/dinov2-base/resolve/main/preprocessor_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/dinov2-base/resolve/main/preprocessor_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FBD0ED1D50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 603267a4-82bd-4ba9-9438-bc0a1ba0c52b)')' thrown while requesting HEAD https://huggingface.co/facebook/dinov2-base/resolve/main/preprocessor_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/dinov2-base/resolve/main/preprocessor_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FBC5330EE0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: b64d53b0-e5c5-4c49-be5d-cfb5de3e1a60)')' thrown while requesting HEAD https://huggingface.co/facebook/dinov2-base/resolve/main/preprocessor_config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/dinov2-base/resolve/main/preprocessor_config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FBFF2673A0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: d9705216-5ccb-479a-af3e-714d1d630c74)')' thrown while requesting HEAD https://huggingface.co/facebook/dinov2-base/resolve/main/preprocessor_config.json\n",
      "Retrying in 8s [Retry 4/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 model initialized.\n",
      "MiniLM model initialized.\n",
      "Loaded 74999 rows\n",
      "Columns in CSV: ['sample_id', 'product_name', 'catalog_content_clean', 'value', 'unit', 'image']\n",
      "DataLoader ready.\n",
      "üîÅ Resuming from batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   0%|          | 1/750 [00:12<2:30:08, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   0%|          | 2/750 [00:26<2:50:14, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   0%|          | 3/750 [00:35<2:23:55, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 4/750 [00:46<2:20:07, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 5/750 [00:58<2:21:48, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 6/750 [01:09<2:19:30, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 7/750 [01:21<2:23:13, 11.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 8/750 [01:32<2:19:53, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|          | 9/750 [01:43<2:17:48, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|‚ñè         | 10/750 [01:53<2:15:43, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   1%|‚ñè         | 11/750 [02:05<2:17:50, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 12/750 [02:15<2:13:37, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 13/750 [02:26<2:14:50, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 14/750 [02:35<2:05:35, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 15/750 [02:42<1:55:20,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 16/750 [02:50<1:47:16,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 17/750 [02:57<1:40:29,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   2%|‚ñè         | 18/750 [03:04<1:37:42,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 19/750 [03:12<1:35:39,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 20/750 [03:19<1:34:20,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 21/750 [03:27<1:34:13,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 22/750 [03:34<1:33:34,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 23/750 [03:42<1:34:25,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 24/750 [03:49<1:31:44,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 25/750 [03:57<1:31:11,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   3%|‚ñé         | 26/750 [04:04<1:29:52,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñé         | 27/750 [04:11<1:28:45,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñé         | 28/750 [04:18<1:27:52,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñç         | 29/750 [04:26<1:28:20,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñç         | 30/750 [04:33<1:28:47,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñç         | 31/750 [04:41<1:29:48,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñç         | 32/750 [04:49<1:29:57,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   4%|‚ñç         | 33/750 [04:56<1:29:00,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñç         | 34/750 [05:04<1:29:33,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñç         | 35/750 [05:12<1:30:40,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñç         | 36/750 [05:20<1:33:20,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñç         | 37/750 [05:28<1:32:36,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñå         | 38/750 [05:36<1:33:40,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñå         | 39/750 [05:44<1:33:38,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñå         | 40/750 [05:51<1:32:03,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   5%|‚ñå         | 41/750 [05:58<1:30:03,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñå         | 42/750 [06:06<1:28:40,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñå         | 43/750 [06:13<1:29:00,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñå         | 44/750 [06:21<1:28:01,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñå         | 45/750 [06:28<1:28:03,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñå         | 46/750 [06:36<1:28:43,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñã         | 47/750 [06:44<1:28:59,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   6%|‚ñã         | 48/750 [06:51<1:28:24,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 49/750 [06:58<1:26:23,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 50/750 [07:05<1:25:40,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 51/750 [07:12<1:24:19,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 52/750 [07:20<1:26:09,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 53/750 [07:27<1:24:45,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 54/750 [07:35<1:25:26,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 55/750 [07:42<1:25:27,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   7%|‚ñã         | 56/750 [07:50<1:27:46,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 57/750 [07:58<1:27:25,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 58/750 [08:07<1:32:01,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 59/750 [08:17<1:40:58,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 60/750 [08:27<1:44:17,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 61/750 [08:37<1:48:19,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 62/750 [08:46<1:47:27,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   8%|‚ñä         | 63/750 [08:55<1:46:08,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñä         | 64/750 [09:05<1:48:30,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñä         | 65/750 [09:15<1:48:08,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 66/750 [09:22<1:41:17,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 67/750 [09:31<1:39:28,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 68/750 [09:39<1:36:04,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 69/750 [09:46<1:31:54,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 70/750 [09:54<1:32:01,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   9%|‚ñâ         | 71/750 [10:03<1:36:11,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñâ         | 72/750 [10:12<1:35:14,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñâ         | 73/750 [10:20<1:35:17,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñâ         | 74/750 [10:28<1:32:43,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñà         | 75/750 [10:36<1:31:46,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñà         | 76/750 [10:45<1:33:30,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñà         | 77/750 [10:53<1:31:54,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  10%|‚ñà         | 78/750 [11:00<1:29:17,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 79/750 [11:08<1:29:04,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 80/750 [11:15<1:27:26,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 81/750 [11:23<1:27:54,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 82/750 [11:31<1:26:51,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 83/750 [11:39<1:25:44,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà         | 84/750 [11:46<1:24:32,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà‚ñè        | 85/750 [11:54<1:24:56,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  11%|‚ñà‚ñè        | 86/750 [12:01<1:23:11,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 87/750 [12:08<1:22:48,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 88/750 [12:16<1:22:53,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 89/750 [12:23<1:21:47,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 90/750 [12:31<1:22:05,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 91/750 [12:39<1:23:28,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 92/750 [12:46<1:23:30,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  12%|‚ñà‚ñè        | 93/750 [12:53<1:21:35,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 94/750 [13:01<1:22:01,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 95/750 [13:09<1:22:47,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 96/750 [13:16<1:22:30,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 97/750 [13:23<1:21:14,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 98/750 [13:31<1:20:19,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 99/750 [13:38<1:20:22,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 100/750 [13:45<1:19:24,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  13%|‚ñà‚ñé        | 101/750 [13:53<1:19:45,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñé        | 102/750 [14:01<1:20:54,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñé        | 103/750 [14:08<1:21:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñç        | 104/750 [14:15<1:19:23,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñç        | 105/750 [14:23<1:20:31,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñç        | 106/750 [14:31<1:22:02,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñç        | 107/750 [14:39<1:22:17,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  14%|‚ñà‚ñç        | 108/750 [14:47<1:22:54,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñç        | 109/750 [14:54<1:23:00,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñç        | 110/750 [15:02<1:22:31,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñç        | 111/750 [15:09<1:20:28,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñç        | 112/750 [15:17<1:20:05,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñå        | 113/750 [15:24<1:20:53,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñå        | 114/750 [15:32<1:19:31,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñå        | 115/750 [15:39<1:17:39,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  15%|‚ñà‚ñå        | 116/750 [15:46<1:18:56,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñå        | 117/750 [15:54<1:17:52,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñå        | 118/750 [16:01<1:17:32,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñå        | 119/750 [16:09<1:18:21,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñå        | 120/750 [16:16<1:18:08,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñå        | 121/750 [16:24<1:18:48,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñã        | 122/750 [16:31<1:17:05,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  16%|‚ñà‚ñã        | 123/750 [16:38<1:16:32,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 124/750 [16:46<1:18:55,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 125/750 [16:53<1:17:57,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 126/750 [17:01<1:18:08,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 127/750 [17:08<1:17:12,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 128/750 [17:16<1:17:40,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 129/750 [17:23<1:18:06,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 130/750 [17:32<1:19:37,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  17%|‚ñà‚ñã        | 131/750 [17:39<1:19:45,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 132/750 [17:47<1:20:34,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 133/750 [17:55<1:19:20,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 134/750 [18:03<1:19:05,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 135/750 [18:10<1:19:15,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 136/750 [18:18<1:20:01,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 137/750 [18:26<1:19:24,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  18%|‚ñà‚ñä        | 138/750 [18:33<1:18:17,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñä        | 139/750 [18:41<1:18:27,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñä        | 140/750 [18:49<1:17:18,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 141/750 [18:56<1:17:37,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 142/750 [19:05<1:20:06,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 143/750 [19:12<1:19:06,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 144/750 [19:20<1:17:16,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 145/750 [19:27<1:17:02,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  19%|‚ñà‚ñâ        | 146/750 [19:35<1:17:52,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñâ        | 147/750 [19:42<1:15:26,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñâ        | 148/750 [19:50<1:14:56,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñâ        | 149/750 [19:58<1:16:29,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñà        | 150/750 [20:06<1:18:03,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñà        | 151/750 [20:14<1:17:46,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñà        | 152/750 [20:21<1:15:58,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñà        | 153/750 [20:29<1:16:28,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 153\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor, AutoModel, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Hugging Face warnings fixes ---\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_XET_WARNING\"] = \"1\"\n",
    "\n",
    "# Enable loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# --- Custom Collate Function ---\n",
    "def custom_collate_fn(batch):\n",
    "    images, texts, prices, sample_ids, image_paths = zip(*batch)\n",
    "    return list(images), list(texts), torch.tensor(prices, dtype=torch.float32), list(sample_ids), list(image_paths)\n",
    "\n",
    "# --- Product Dataset ---\n",
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, df, image_folder, has_price=False):\n",
    "        self.df = df\n",
    "        self.image_folder = Path(image_folder)\n",
    "        self.has_price = has_price  # Test dataset does not have price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_name = str(row['image']).strip()  # remove stray spaces/tabs/newlines\n",
    "        image_path = self.image_folder / image_name\n",
    "        sample_id = row['sample_id']\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading image {image_path} (sample_id: {sample_id}): {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))  # fallback black image\n",
    "\n",
    "        text = row.get('catalog_content_clean', \"No description available\")\n",
    "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "            text = \"No description available\"\n",
    "\n",
    "        price = float(row['price']) if self.has_price else 0.0\n",
    "        return img, text, price, sample_id, str(image_path)\n",
    "\n",
    "# --- Embedding Extraction ---\n",
    "def extract_and_save_embeddings(image_model, text_model, image_processor, text_tokenizer, data_loader, save_dir, max_length=128):\n",
    "    image_model.eval()\n",
    "    text_model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Detect last processed batch\n",
    "    existing_batches = [\n",
    "        int(f.split('_')[1])\n",
    "        for f in os.listdir(save_dir)\n",
    "        if f.startswith('batch_') and os.path.isdir(os.path.join(save_dir, f))\n",
    "    ]\n",
    "    start_batch = max(existing_batches) + 1 if existing_batches else 0\n",
    "    print(f\"üîÅ Resuming from batch {start_batch}\")\n",
    "\n",
    "    metadata_path = os.path.join(save_dir, 'metadata.csv')\n",
    "    processed_sample_ids = set()\n",
    "    if os.path.exists(metadata_path):\n",
    "        processed_metadata = pd.read_csv(metadata_path)\n",
    "        processed_sample_ids = set(processed_metadata['sample_id'])\n",
    "        print(f\"Found {len(processed_sample_ids)} processed samples\")\n",
    "\n",
    "    all_image_embeddings = []\n",
    "    all_text_embeddings = []\n",
    "    all_sample_ids = []\n",
    "    all_image_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_images, batch_texts, batch_prices, batch_sample_ids, batch_image_paths) in enumerate(\n",
    "            tqdm(data_loader, desc=\"Extracting embeddings\")\n",
    "        ):\n",
    "            if batch_idx < start_batch:\n",
    "                continue\n",
    "            if all(sample_id in processed_sample_ids for sample_id in batch_sample_ids):\n",
    "                print(f\"Skipping batch {batch_idx} (already processed)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing batch {batch_idx}\")\n",
    "\n",
    "            # Image embeddings\n",
    "            try:\n",
    "                inputs = image_processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "                image_emb = image_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing image embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Text embeddings\n",
    "            try:\n",
    "                inputs = text_tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "                text_emb = text_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing text embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Save batch embeddings\n",
    "            batch_save_dir = os.path.join(save_dir, f'batch_{batch_idx}')\n",
    "            os.makedirs(batch_save_dir, exist_ok=True)\n",
    "            torch.save(torch.tensor(image_emb), os.path.join(batch_save_dir, 'image_embeddings.pt'))\n",
    "            torch.save(torch.tensor(text_emb), os.path.join(batch_save_dir, 'text_embeddings.pt'))\n",
    "\n",
    "            all_image_embeddings.append(image_emb)\n",
    "            all_text_embeddings.append(text_emb)\n",
    "            all_sample_ids.extend(batch_sample_ids)\n",
    "            all_image_paths.extend(batch_image_paths)\n",
    "\n",
    "    # Save consolidated embeddings\n",
    "    all_image_emb_path = os.path.join(save_dir, 'all_image_embeddings.pt')\n",
    "    all_text_emb_path = os.path.join(save_dir, 'all_text_embeddings.pt')\n",
    "\n",
    "    if all_image_embeddings:\n",
    "        all_image_embeddings = np.concatenate(all_image_embeddings, axis=0)\n",
    "        all_text_embeddings = np.concatenate(all_text_embeddings, axis=0)\n",
    "\n",
    "        if os.path.exists(all_image_emb_path) and os.path.exists(all_text_emb_path):\n",
    "            existing_image_emb = torch.load(all_image_emb_path).numpy()\n",
    "            existing_text_emb = torch.load(all_text_emb_path).numpy()\n",
    "            all_image_embeddings = np.concatenate([existing_image_emb, all_image_embeddings], axis=0)\n",
    "            all_text_embeddings = np.concatenate([existing_text_emb, all_text_embeddings], axis=0)\n",
    "\n",
    "        torch.save(torch.tensor(all_image_embeddings), all_image_emb_path)\n",
    "        torch.save(torch.tensor(all_text_embeddings), all_text_emb_path)\n",
    "\n",
    "        new_metadata = pd.DataFrame({\n",
    "            'index': range(len(all_sample_ids)),\n",
    "            'sample_id': all_sample_ids,\n",
    "            'image_path': all_image_paths\n",
    "        })\n",
    "\n",
    "        if os.path.exists(metadata_path):\n",
    "            existing_metadata = pd.read_csv(metadata_path)\n",
    "            new_metadata = pd.concat([existing_metadata, new_metadata], ignore_index=True)\n",
    "        new_metadata.to_csv(metadata_path, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Embeddings saved to {save_dir}\")\n",
    "    if all_image_embeddings:\n",
    "        print(f\"Image embeddings shape: {all_image_embeddings.shape} ([num_samples, 257, 768])\")\n",
    "        print(f\"Text embeddings shape: {all_text_embeddings.shape} ([num_samples, {max_length}, 384])\")\n",
    "    else:\n",
    "        print(\"No new embeddings generated (all batches skipped or empty)\")\n",
    "\n",
    "# --- Main Script ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load models\n",
    "image_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base', use_fast=True)\n",
    "image_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "print(\"DINOv2 model initialized.\")\n",
    "\n",
    "text_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "text_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2').to(device)\n",
    "print(\"MiniLM model initialized.\")\n",
    "\n",
    "# Paths\n",
    "EMBEDDINGS_DIR = './test_embeddings/'\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_FOLDER = 'test_images/test_images'  # Folder with all images\n",
    "df = pd.read_csv(\"test/merged_test_with_image.csv\")\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(\"Columns in CSV:\", df.columns.tolist())\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ProductDataset(df, IMAGE_FOLDER, has_price=False)\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "print(\"DataLoader ready.\")\n",
    "\n",
    "# Extract and save embeddings\n",
    "extract_and_save_embeddings(\n",
    "    image_model, text_model, image_processor, text_tokenizer,\n",
    "    data_loader, EMBEDDINGS_DIR, max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28e0031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 model initialized.\n",
      "MiniLM model initialized.\n",
      "Loaded 74999 rows\n",
      "Columns in CSV: ['sample_id', 'product_name', 'catalog_content_clean', 'value', 'unit', 'image']\n",
      "DataLoader ready.\n",
      "üîÅ Resuming from batch 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  20%|‚ñà‚ñà        | 153/750 [05:09<19:06,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 154/750 [05:15<33:10,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 155/750 [05:22<43:10,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 156/750 [05:29<50:53,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 157/750 [05:36<57:59,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 158/750 [05:43<1:01:11,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà        | 159/750 [05:50<1:02:49,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà‚ñè       | 160/750 [05:57<1:04:01,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  21%|‚ñà‚ñà‚ñè       | 161/750 [06:04<1:05:24,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 162/750 [06:11<1:05:42,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 163/750 [06:18<1:05:55,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 164/750 [06:25<1:05:57,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 165/750 [06:32<1:07:26,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 166/750 [06:39<1:08:13,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 167/750 [06:46<1:08:31,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  22%|‚ñà‚ñà‚ñè       | 168/750 [06:54<1:09:54,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 169/750 [07:01<1:09:08,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 170/750 [07:08<1:08:23,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 171/750 [07:14<1:07:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 172/750 [07:21<1:07:35,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 173/750 [07:28<1:06:29,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 174/750 [07:36<1:08:05,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 175/750 [07:43<1:09:03,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  23%|‚ñà‚ñà‚ñé       | 176/750 [07:51<1:10:08,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñé       | 177/750 [07:58<1:08:21,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñé       | 178/750 [08:04<1:07:34,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñç       | 179/750 [08:11<1:06:37,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñç       | 180/750 [08:19<1:08:18,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñç       | 181/750 [08:26<1:09:16,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñç       | 182/750 [08:34<1:08:54,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  24%|‚ñà‚ñà‚ñç       | 183/750 [08:41<1:09:15,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñç       | 184/750 [08:48<1:09:11,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñç       | 185/750 [08:55<1:07:58,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñç       | 186/750 [09:03<1:08:24,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñç       | 187/750 [09:11<1:10:47,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñå       | 188/750 [09:18<1:10:29,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñå       | 189/750 [09:26<1:09:28,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñå       | 190/750 [09:33<1:09:13,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  25%|‚ñà‚ñà‚ñå       | 191/750 [09:41<1:09:22,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñå       | 192/750 [09:48<1:09:52,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñå       | 193/750 [09:56<1:09:49,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñå       | 194/750 [10:03<1:08:05,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñå       | 195/750 [10:10<1:06:44,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñå       | 196/750 [10:17<1:05:56,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñã       | 197/750 [10:24<1:06:43,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  26%|‚ñà‚ñà‚ñã       | 198/750 [10:32<1:07:27,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 199/750 [10:39<1:07:32,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 200/750 [10:46<1:05:19,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 201/750 [10:53<1:05:43,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 202/750 [11:01<1:06:55,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 203/750 [11:08<1:06:30,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 204/750 [11:15<1:06:11,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 205/750 [11:23<1:06:37,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  27%|‚ñà‚ñà‚ñã       | 206/750 [11:30<1:07:28,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 207/750 [11:38<1:08:04,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 208/750 [11:45<1:07:43,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 209/750 [11:53<1:06:54,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 210/750 [12:00<1:07:06,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 211/750 [12:08<1:07:09,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 212/750 [12:15<1:07:55,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  28%|‚ñà‚ñà‚ñä       | 213/750 [12:23<1:08:04,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñä       | 214/750 [12:31<1:07:51,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñä       | 215/750 [12:39<1:09:23,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 216/750 [12:47<1:09:38,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 217/750 [12:54<1:08:02,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 218/750 [13:01<1:06:48,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 219/750 [13:09<1:07:17,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 220/750 [13:16<1:06:17,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  29%|‚ñà‚ñà‚ñâ       | 221/750 [13:23<1:04:37,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñâ       | 222/750 [13:31<1:04:56,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñâ       | 223/750 [13:39<1:05:46,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñâ       | 224/750 [13:47<1:08:22,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñà       | 225/750 [13:54<1:06:49,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñà       | 226/750 [14:01<1:05:16,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñà       | 227/750 [14:09<1:05:28,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  30%|‚ñà‚ñà‚ñà       | 228/750 [14:18<1:09:00,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 229/750 [14:25<1:07:27,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 230/750 [14:33<1:07:18,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 231/750 [14:41<1:06:17,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 232/750 [14:48<1:05:19,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 233/750 [14:55<1:04:25,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà       | 234/750 [15:02<1:03:53,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà‚ñè      | 235/750 [15:11<1:05:24,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  31%|‚ñà‚ñà‚ñà‚ñè      | 236/750 [15:18<1:04:46,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 237/750 [15:25<1:04:00,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 238/750 [15:32<1:02:58,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 239/750 [15:40<1:02:41,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 240/750 [15:48<1:04:08,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 241/750 [15:55<1:03:14,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 242/750 [16:02<1:02:40,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  32%|‚ñà‚ñà‚ñà‚ñè      | 243/750 [16:10<1:03:44,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 244/750 [16:18<1:03:18,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 245/750 [16:25<1:03:09,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 246/750 [16:33<1:03:00,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 247/750 [16:41<1:04:22,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 248/750 [16:48<1:04:48,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 249/750 [16:56<1:04:50,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 250/750 [17:04<1:04:17,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  33%|‚ñà‚ñà‚ñà‚ñé      | 251/750 [17:11<1:03:02,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñé      | 252/750 [17:18<1:02:07,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñé      | 253/750 [17:26<1:02:52,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñç      | 254/750 [17:34<1:02:11,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñç      | 255/750 [17:41<1:02:22,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñç      | 256/750 [17:49<1:01:56,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñç      | 257/750 [17:56<1:02:11,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  34%|‚ñà‚ñà‚ñà‚ñç      | 258/750 [18:03<1:00:51,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñç      | 259/750 [18:11<1:01:25,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñç      | 260/750 [18:19<1:02:28,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñç      | 261/750 [18:27<1:02:01,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñç      | 262/750 [18:34<1:02:02,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñå      | 263/750 [18:42<1:00:56,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñå      | 264/750 [18:49<1:00:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñå      | 265/750 [18:56<1:00:00,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  35%|‚ñà‚ñà‚ñà‚ñå      | 266/750 [19:04<1:00:36,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñå      | 267/750 [19:12<1:00:49,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñå      | 268/750 [19:20<1:02:21,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñå      | 269/750 [19:27<1:01:29,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñå      | 270/750 [19:35<1:00:41,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñå      | 271/750 [19:42<59:54,  7.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñã      | 272/750 [19:50<1:00:11,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  36%|‚ñà‚ñà‚ñà‚ñã      | 273/750 [19:57<59:59,  7.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 274/750 [20:05<1:00:30,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 275/750 [20:12<59:51,  7.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 276/750 [20:20<58:40,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 277/750 [20:27<59:08,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 278/750 [20:35<58:33,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 279/750 [20:41<56:53,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 280/750 [20:49<56:42,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  37%|‚ñà‚ñà‚ñà‚ñã      | 281/750 [20:56<57:17,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 282/750 [21:03<57:11,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 283/750 [21:11<57:35,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 284/750 [21:19<58:37,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 285/750 [21:26<57:57,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 286/750 [21:34<58:39,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 287/750 [21:42<58:55,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  38%|‚ñà‚ñà‚ñà‚ñä      | 288/750 [21:49<58:24,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñä      | 289/750 [21:57<58:27,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñä      | 290/750 [22:05<58:20,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 291/750 [22:11<56:36,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 292/750 [22:19<56:17,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 293/750 [22:27<58:00,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 294/750 [22:34<57:39,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 295/750 [22:42<57:14,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  39%|‚ñà‚ñà‚ñà‚ñâ      | 296/750 [22:49<56:23,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñâ      | 297/750 [22:56<55:42,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñâ      | 298/750 [23:04<55:30,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñâ      | 299/750 [23:11<56:01,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñà      | 300/750 [23:19<55:33,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñà      | 301/750 [23:26<54:56,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñà      | 302/750 [23:33<54:24,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñà      | 303/750 [23:41<55:48,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  41%|‚ñà‚ñà‚ñà‚ñà      | 304/750 [23:48<55:42,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 304\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor, AutoModel, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Hugging Face warnings fixes ---\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_XET_WARNING\"] = \"1\"\n",
    "\n",
    "# Enable loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# --- Custom Collate Function ---\n",
    "def custom_collate_fn(batch):\n",
    "    images, texts, prices, sample_ids, image_paths = zip(*batch)\n",
    "    return list(images), list(texts), torch.tensor(prices, dtype=torch.float32), list(sample_ids), list(image_paths)\n",
    "\n",
    "# --- Product Dataset ---\n",
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, df, image_folder, has_price=False):\n",
    "        self.df = df\n",
    "        self.image_folder = Path(image_folder)\n",
    "        self.has_price = has_price  # Test dataset does not have price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_name = str(row['image']).strip()  # remove stray spaces/tabs/newlines\n",
    "        image_path = self.image_folder / image_name\n",
    "        sample_id = row['sample_id']\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading image {image_path} (sample_id: {sample_id}): {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))  # fallback black image\n",
    "\n",
    "        text = row.get('catalog_content_clean', \"No description available\")\n",
    "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "            text = \"No description available\"\n",
    "\n",
    "        price = float(row['price']) if self.has_price else 0.0\n",
    "        return img, text, price, sample_id, str(image_path)\n",
    "\n",
    "# --- Embedding Extraction ---\n",
    "def extract_and_save_embeddings(image_model, text_model, image_processor, text_tokenizer, data_loader, save_dir, max_length=128):\n",
    "    image_model.eval()\n",
    "    text_model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Detect last processed batch\n",
    "    existing_batches = [\n",
    "        int(f.split('_')[1])\n",
    "        for f in os.listdir(save_dir)\n",
    "        if f.startswith('batch_') and os.path.isdir(os.path.join(save_dir, f))\n",
    "    ]\n",
    "    start_batch = max(existing_batches) + 1 if existing_batches else 0\n",
    "    print(f\"üîÅ Resuming from batch {start_batch}\")\n",
    "\n",
    "    metadata_path = os.path.join(save_dir, 'metadata.csv')\n",
    "    processed_sample_ids = set()\n",
    "    if os.path.exists(metadata_path):\n",
    "        processed_metadata = pd.read_csv(metadata_path)\n",
    "        processed_sample_ids = set(processed_metadata['sample_id'])\n",
    "        print(f\"Found {len(processed_sample_ids)} processed samples\")\n",
    "\n",
    "    all_image_embeddings = []\n",
    "    all_text_embeddings = []\n",
    "    all_sample_ids = []\n",
    "    all_image_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_images, batch_texts, batch_prices, batch_sample_ids, batch_image_paths) in enumerate(\n",
    "            tqdm(data_loader, desc=\"Extracting embeddings\")\n",
    "        ):\n",
    "            if batch_idx < start_batch:\n",
    "                continue\n",
    "            if all(sample_id in processed_sample_ids for sample_id in batch_sample_ids):\n",
    "                print(f\"Skipping batch {batch_idx} (already processed)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing batch {batch_idx}\")\n",
    "\n",
    "            # Image embeddings\n",
    "            try:\n",
    "                inputs = image_processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "                image_emb = image_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing image embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Text embeddings\n",
    "            try:\n",
    "                inputs = text_tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "                text_emb = text_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing text embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Save batch embeddings\n",
    "            batch_save_dir = os.path.join(save_dir, f'batch_{batch_idx}')\n",
    "            os.makedirs(batch_save_dir, exist_ok=True)\n",
    "            torch.save(torch.tensor(image_emb), os.path.join(batch_save_dir, 'image_embeddings.pt'))\n",
    "            torch.save(torch.tensor(text_emb), os.path.join(batch_save_dir, 'text_embeddings.pt'))\n",
    "\n",
    "            all_image_embeddings.append(image_emb)\n",
    "            all_text_embeddings.append(text_emb)\n",
    "            all_sample_ids.extend(batch_sample_ids)\n",
    "            all_image_paths.extend(batch_image_paths)\n",
    "\n",
    "    # Save consolidated embeddings\n",
    "    all_image_emb_path = os.path.join(save_dir, 'all_image_embeddings.pt')\n",
    "    all_text_emb_path = os.path.join(save_dir, 'all_text_embeddings.pt')\n",
    "\n",
    "    if all_image_embeddings:\n",
    "        all_image_embeddings = np.concatenate(all_image_embeddings, axis=0)\n",
    "        all_text_embeddings = np.concatenate(all_text_embeddings, axis=0)\n",
    "\n",
    "        if os.path.exists(all_image_emb_path) and os.path.exists(all_text_emb_path):\n",
    "            existing_image_emb = torch.load(all_image_emb_path).numpy()\n",
    "            existing_text_emb = torch.load(all_text_emb_path).numpy()\n",
    "            all_image_embeddings = np.concatenate([existing_image_emb, all_image_embeddings], axis=0)\n",
    "            all_text_embeddings = np.concatenate([existing_text_emb, all_text_embeddings], axis=0)\n",
    "\n",
    "        torch.save(torch.tensor(all_image_embeddings), all_image_emb_path)\n",
    "        torch.save(torch.tensor(all_text_embeddings), all_text_emb_path)\n",
    "\n",
    "        new_metadata = pd.DataFrame({\n",
    "            'index': range(len(all_sample_ids)),\n",
    "            'sample_id': all_sample_ids,\n",
    "            'image_path': all_image_paths\n",
    "        })\n",
    "\n",
    "        if os.path.exists(metadata_path):\n",
    "            existing_metadata = pd.read_csv(metadata_path)\n",
    "            new_metadata = pd.concat([existing_metadata, new_metadata], ignore_index=True)\n",
    "        new_metadata.to_csv(metadata_path, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Embeddings saved to {save_dir}\")\n",
    "    if all_image_embeddings:\n",
    "        print(f\"Image embeddings shape: {all_image_embeddings.shape} ([num_samples, 257, 768])\")\n",
    "        print(f\"Text embeddings shape: {all_text_embeddings.shape} ([num_samples, {max_length}, 384])\")\n",
    "    else:\n",
    "        print(\"No new embeddings generated (all batches skipped or empty)\")\n",
    "\n",
    "# --- Main Script ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load models\n",
    "image_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base', use_fast=True)\n",
    "image_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "print(\"DINOv2 model initialized.\")\n",
    "\n",
    "text_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "text_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2').to(device)\n",
    "print(\"MiniLM model initialized.\")\n",
    "\n",
    "# Paths\n",
    "EMBEDDINGS_DIR = './test_embeddings/'\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_FOLDER = 'test_images/test_images'  # Folder with all images\n",
    "df = pd.read_csv(\"test/merged_test_with_image.csv\")\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(\"Columns in CSV:\", df.columns.tolist())\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ProductDataset(df, IMAGE_FOLDER, has_price=False)\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "print(\"DataLoader ready.\")\n",
    "\n",
    "# Extract and save embeddings\n",
    "extract_and_save_embeddings(\n",
    "    image_model, text_model, image_processor, text_tokenizer,\n",
    "    data_loader, EMBEDDINGS_DIR, max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47f2d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 model initialized.\n",
      "MiniLM model initialized.\n",
      "Loaded 74999 rows\n",
      "Columns in CSV: ['sample_id', 'product_name', 'catalog_content_clean', 'value', 'unit', 'image']\n",
      "DataLoader ready.\n",
      "üîÅ Resuming from batch 573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:  40%|‚ñà‚ñà‚ñà‚ñà      | 302/750 [21:29<31:52,  4.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 181\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader ready.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Extract and save embeddings\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mextract_and_save_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEMBEDDINGS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[0;32m    184\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 81\u001b[0m, in \u001b[0;36mextract_and_save_embeddings\u001b[1;34m(image_model, text_model, image_processor, text_tokenizer, data_loader, save_dir, max_length)\u001b[0m\n\u001b[0;32m     78\u001b[0m all_image_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (batch_images, batch_texts, batch_prices, batch_sample_ids, batch_image_paths) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[0;32m     82\u001b[0m         tqdm(data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     ):\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m<\u001b[39m start_batch:\n\u001b[0;32m     85\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mProductDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     38\u001b[0m sample_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Error loading image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (sample_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\PIL\\Image.py:922\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m    876\u001b[0m ):\n\u001b[0;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\harsh\\miniconda3\\envs\\battery\\lib\\site-packages\\PIL\\ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor, AutoModel, AutoTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Hugging Face warnings fixes ---\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_XET_WARNING\"] = \"1\"\n",
    "\n",
    "# Enable loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# --- Custom Collate Function ---\n",
    "def custom_collate_fn(batch):\n",
    "    images, texts, prices, sample_ids, image_paths = zip(*batch)\n",
    "    return list(images), list(texts), torch.tensor(prices, dtype=torch.float32), list(sample_ids), list(image_paths)\n",
    "\n",
    "# --- Product Dataset ---\n",
    "class ProductDataset(Dataset):\n",
    "    def __init__(self, df, image_folder, has_price=False):\n",
    "        self.df = df\n",
    "        self.image_folder = Path(image_folder)\n",
    "        self.has_price = has_price  # Test dataset does not have price\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_name = str(row['image']).strip()  # remove stray spaces/tabs/newlines\n",
    "        image_path = self.image_folder / image_name\n",
    "        sample_id = row['sample_id']\n",
    "\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading image {image_path} (sample_id: {sample_id}): {e}\")\n",
    "            img = Image.new('RGB', (224, 224), (0, 0, 0))  # fallback black image\n",
    "\n",
    "        text = row.get('catalog_content_clean', \"No description available\")\n",
    "        if pd.isna(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "            text = \"No description available\"\n",
    "\n",
    "        price = float(row['price']) if self.has_price else 0.0\n",
    "        return img, text, price, sample_id, str(image_path)\n",
    "\n",
    "# --- Embedding Extraction ---\n",
    "def extract_and_save_embeddings(image_model, text_model, image_processor, text_tokenizer, data_loader, save_dir, max_length=128):\n",
    "    image_model.eval()\n",
    "    text_model.eval()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Detect last processed batch\n",
    "    existing_batches = [\n",
    "        int(f.split('_')[1])\n",
    "        for f in os.listdir(save_dir)\n",
    "        if f.startswith('batch_') and os.path.isdir(os.path.join(save_dir, f))\n",
    "    ]\n",
    "    start_batch = max(existing_batches) + 1 if existing_batches else 0\n",
    "    print(f\"üîÅ Resuming from batch {start_batch}\")\n",
    "\n",
    "    metadata_path = os.path.join(save_dir, 'metadata.csv')\n",
    "    processed_sample_ids = set()\n",
    "    if os.path.exists(metadata_path):\n",
    "        processed_metadata = pd.read_csv(metadata_path)\n",
    "        processed_sample_ids = set(processed_metadata['sample_id'])\n",
    "        print(f\"Found {len(processed_sample_ids)} processed samples\")\n",
    "\n",
    "    all_image_embeddings = []\n",
    "    all_text_embeddings = []\n",
    "    all_sample_ids = []\n",
    "    all_image_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (batch_images, batch_texts, batch_prices, batch_sample_ids, batch_image_paths) in enumerate(\n",
    "            tqdm(data_loader, desc=\"Extracting embeddings\")\n",
    "        ):\n",
    "            if batch_idx < start_batch:\n",
    "                continue\n",
    "            if all(sample_id in processed_sample_ids for sample_id in batch_sample_ids):\n",
    "                print(f\"Skipping batch {batch_idx} (already processed)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing batch {batch_idx}\")\n",
    "\n",
    "            # Image embeddings\n",
    "            try:\n",
    "                inputs = image_processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "                image_emb = image_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing image embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Text embeddings\n",
    "            try:\n",
    "                inputs = text_tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "                text_emb = text_model(**inputs).last_hidden_state.cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing text embeddings for batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Save batch embeddings\n",
    "            batch_save_dir = os.path.join(save_dir, f'batch_{batch_idx}')\n",
    "            os.makedirs(batch_save_dir, exist_ok=True)\n",
    "            torch.save(torch.tensor(image_emb), os.path.join(batch_save_dir, 'image_embeddings.pt'))\n",
    "            torch.save(torch.tensor(text_emb), os.path.join(batch_save_dir, 'text_embeddings.pt'))\n",
    "\n",
    "            all_image_embeddings.append(image_emb)\n",
    "            all_text_embeddings.append(text_emb)\n",
    "            all_sample_ids.extend(batch_sample_ids)\n",
    "            all_image_paths.extend(batch_image_paths)\n",
    "\n",
    "    # Save consolidated embeddings\n",
    "    all_image_emb_path = os.path.join(save_dir, 'all_image_embeddings.pt')\n",
    "    all_text_emb_path = os.path.join(save_dir, 'all_text_embeddings.pt')\n",
    "\n",
    "    if all_image_embeddings:\n",
    "        all_image_embeddings = np.concatenate(all_image_embeddings, axis=0)\n",
    "        all_text_embeddings = np.concatenate(all_text_embeddings, axis=0)\n",
    "\n",
    "        if os.path.exists(all_image_emb_path) and os.path.exists(all_text_emb_path):\n",
    "            existing_image_emb = torch.load(all_image_emb_path).numpy()\n",
    "            existing_text_emb = torch.load(all_text_emb_path).numpy()\n",
    "            all_image_embeddings = np.concatenate([existing_image_emb, all_image_embeddings], axis=0)\n",
    "            all_text_embeddings = np.concatenate([existing_text_emb, all_text_embeddings], axis=0)\n",
    "\n",
    "        torch.save(torch.tensor(all_image_embeddings), all_image_emb_path)\n",
    "        torch.save(torch.tensor(all_text_embeddings), all_text_emb_path)\n",
    "\n",
    "        new_metadata = pd.DataFrame({\n",
    "            'index': range(len(all_sample_ids)),\n",
    "            'sample_id': all_sample_ids,\n",
    "            'image_path': all_image_paths\n",
    "        })\n",
    "\n",
    "        if os.path.exists(metadata_path):\n",
    "            existing_metadata = pd.read_csv(metadata_path)\n",
    "            new_metadata = pd.concat([existing_metadata, new_metadata], ignore_index=True)\n",
    "        new_metadata.to_csv(metadata_path, index=False)\n",
    "\n",
    "    print(f\"‚úÖ Embeddings saved to {save_dir}\")\n",
    "    if all_image_embeddings:\n",
    "        print(f\"Image embeddings shape: {all_image_embeddings.shape} ([num_samples, 257, 768])\")\n",
    "        print(f\"Text embeddings shape: {all_text_embeddings.shape} ([num_samples, {max_length}, 384])\")\n",
    "    else:\n",
    "        print(\"No new embeddings generated (all batches skipped or empty)\")\n",
    "\n",
    "# --- Main Script ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load models\n",
    "image_processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base', use_fast=True)\n",
    "image_model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "print(\"DINOv2 model initialized.\")\n",
    "\n",
    "text_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "text_model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2').to(device)\n",
    "print(\"MiniLM model initialized.\")\n",
    "\n",
    "# Paths\n",
    "EMBEDDINGS_DIR = './test_embeddings/'\n",
    "os.makedirs(EMBEDDINGS_DIR, exist_ok=True)\n",
    "\n",
    "IMAGE_FOLDER = 'test_images/test_images'  # Folder with all images\n",
    "df = pd.read_csv(\"test/merged_test_with_image.csv\")\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(\"Columns in CSV:\", df.columns.tolist())\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ProductDataset(df, IMAGE_FOLDER, has_price=False)\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=False, num_workers=0, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "print(\"DataLoader ready.\")\n",
    "\n",
    "# Extract and save embeddings\n",
    "extract_and_save_embeddings(\n",
    "    image_model, text_model, image_processor, text_tokenizer,\n",
    "    data_loader, EMBEDDINGS_DIR, max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad0d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "battery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
